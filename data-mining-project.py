# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBGDdJRIu5yLKpc09YNi8yLBrK1XpOPq

# **Project1 - Data Mining**

**Δανάη Καραγεωργοπούλου - sdi2000067**

**Μυρτώ Παράφορου - sdi2000261**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import sys
import matplotlib.pyplot as plt
import numpy as np

path = '/content/drive/MyDrive/dataMining/marketing_campaign.csv'
df = pd.read_csv(path,sep="\t", header=0)
df

"""QUESTION 1"""

# check for missing values
missing_values = df.isnull().sum()

# print the number of missing values in each column
print(missing_values)

df.fillna(-1, inplace=True)
df

# Check for missing values
missing_values = df.isnull().sum()

# Print the number of missing values in each column
print(missing_values)

df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format='%d-%m-%Y')
df

for col in df.columns:
  if df[col].dtype == 'object':
    unique_objects = df[col].unique()
    mapping_dict = {obj: i for i, obj in enumerate(unique_objects)}
    df[col] = df[col].map(mapping_dict)

"""QUESTION 2"""

# print unique values of Education and Marital_Status
print(df['Education'].unique())
print(df['Marital_Status'].unique())

for index, row in df.iterrows():
  if(row['Marital_Status'] == 5 or row['Marital_Status'] == 6 or row['Marital_Status'] == 7):
    df.at[index, 'Marital_Status'] = 0

df

# plot Marital_Status & Education

import matplotlib.pyplot as plt

value_counts_marital = df['Marital_Status'].value_counts().sort_index()
value_counts_education = df['Education'].value_counts().sort_index()

value_counts_marital.plot.bar()
plt.xlabel('Marital Status')
plt.ylabel('Frequency')
plt.xticks(rotation=0)
plt.show()

value_counts_education.plot.bar()
plt.xlabel('Education')
plt.ylabel('Frequency')
plt.xticks(rotation=0)
plt.show()

"""QUESTION 3

a.
"""

from datetime import datetime

df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])

# Calculate the total number of days since each customer started buying from the company
today = datetime.now()
df['Customer_For'] = (today - df['Dt_Customer']).dt.days

df

"""b."""

import datetime

current_year = datetime.date.today().year
df['Age'] = current_year - df['Year_Birth']
df['Age']

"""c."""

cols_to_sum = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']
df['Spent'] = df[cols_to_sum].sum(axis=1)
df

"""d."""

df['Total_Children'] = df['Kidhome'] + df['Teenhome']
df

"""e."""

df['Family_Size'] = ' '
family_size = 0
for index, row in df.iterrows():
  if(row['Marital_Status'] == 1 or row['Marital_Status'] == 2):
    family_size = row['Total_Children'] + 2
  else: family_size = row['Total_Children'] + 1

  df.at[index, 'Family_Size'] = family_size

df

"""st."""

df['IsParent'] = ''

for index, row in df.iterrows():
  if (row['Total_Children'] > 0):
    df.at[index, 'IsParent'] = 1
  else:
    df.at[index, 'IsParent'] = 0
df

"""z.

"""

for index, row in df.iterrows():
  if(row['Marital_Status'] == 1 or row['Marital_Status'] == 2):
    living_with = 'Together'
  else: living_with = 'Alone'

  df.at[index, 'Living_With'] = living_with

df

"""h."""

df['Age Group'] = ''
for index, row in df.iterrows():
    age = row['Age']
    if age >= 21 and age < 30:
        df.at[index, 'Age Group'] = "21-30"
    elif age >= 31 and age < 40:
        df.at[index, 'Age Group'] = '31-40'
    elif age >= 41 and age < 50:
        df.at[index, 'Age Group'] = '41-50'
    elif age >= 51 and age < 60:
        df.at[index, 'Age Group'] = '51-60'
    elif age >= 61 and age < 70:
        df.at[index, 'Age Group'] = '61-70'
    elif age >= 71 and age < 80:
        df.at[index, 'Age Group'] = '71-80'
    else:
        df.at[index, 'Age Group'] = '>80'
df

"""QUESTION 4

We make the assumption that the non-categorical columns are normally distributed. We consider outlier values all those values that have a standard deviation outside of the [-3,3] interval so they belong to the 0,2% of all values that spread out the most from the y-axis (approximately). We set all those values as nan.
"""

non_categorical_cols = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']

column_means = df.mean(numeric_only=True)
column_stddevs = df.std(numeric_only=True)

for column in non_categorical_cols:
    lower_bound = column_means[column] - 3 * column_stddevs[column]
    upper_bound = column_means[column] + 3 * column_stddevs[column]
    df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), np.nan, df[column])

"""QUESTION 5"""

import seaborn as sns

selectedcol = ['ID', 'Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Dt_Customer', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']
df_heatmap = df[selectedcol]
corr = df_heatmap.corr(numeric_only=True)
sns.heatmap(corr, annot=True, cmap='coolwarm', annot_kws={"fontsize":4})
plt.title('Correlation Heatmap', fontsize=13)
plt.show()

"""QUESTION 6

1.
"""

value_counts_marital = df['Marital_Status'].value_counts().sort_index()

value_counts_marital.plot.bar(color='#E60073')
plt.xlabel('Marital Status')
plt.ylabel('Amount')
plt.xticks(rotation=0)
plt.show()

complaint_counts = df['Complain'].value_counts()
colors = ['#FFC6C6', '#E91E63']
labels = list(complaint_counts.index)
plt.pie(complaint_counts, labels=labels, colors=colors, autopct='%1.1f%%')
plt.title('Complaint Proportion')
plt.show()

"""3.


"""

x = df['Spent']
y = df['Marital_Status']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('Spent')
plt.ylabel('Marital Status')
plt.title('Scatter Plot of Spent vs Marital Status')
plt.show()

"""4."""

sns.scatterplot(data=df, x='Spent', y='Marital_Status', hue='Family_Size')
plt.xlabel('Spent')
plt.ylabel('Marital_Status')
plt.legend(title='Legend Title')
plt.show()

"""5."""

x = df['Spent']
y = df['Age Group']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('Spent')
plt.ylabel('Age Group')
plt.title('Scatter Plot of Spent vs Age Group')
plt.show()

"""6."""

x = df['Income']
y = df['Spent']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('Income')
plt.ylabel('Spent')
plt.title('Scatter Plot of Income vs Spent')
plt.show()

"""7."""

x = df['Education']
y = df['Income']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('Education')
plt.ylabel('Income')
plt.title('Scatter Plot of Education vs Income')
plt.show()

"""8."""

x = df['Income']
y = df['Family_Size']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('Income')
plt.ylabel('Family_Size')
plt.title('Scatter Plot of Income vs Family_Size')
plt.show()

"""9.

"""

x = df['Income']
y = df['Family_Size']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('Income')
plt.ylabel('Family_Size')
plt.title('Scatter Plot of Income vs Family_Size')
plt.show()

"""12."""

x = df['NumWebVisitsMonth']
y = df['NumWebPurchases']

plt.scatter(x, y, color='#E91E63', s=20)
plt.xlabel('NumWebVisitsMonth')
plt.ylabel('NumWebPurchases')
plt.title('Scatter Plot of Income vs Family_Size')
plt.show()

"""7. Principal component analysis"""

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['Education_Encoded'] = encoder.fit_transform(df['Education'])
df['Marital_Status_Encoded'] = encoder.fit_transform(df['Marital_Status'])
df['Living_With_Encoded'] = encoder.fit_transform(df['Living_With'])
df

# Create a copy of the dataframe and drop some specific columns
new_df = df.copy()
columns_to_drop = ['Education', 'Marital_Status', 'Living_With', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Response']
new_df = new_df.drop(columns_to_drop, axis=1)
new_df

min_date = new_df['Dt_Customer'].min()
new_df['seconds'] = (new_df['Dt_Customer'] - min_date).dt.total_seconds()
new_df = new_df.drop(['Dt_Customer'], axis=1)

# replace empty values with NaN and fill missing values with the mean of the column
new_df = new_df.replace('', np.nan)
new_df = new_df.fillna(new_df.mean(numeric_only=True))

# strings are not accepted
new_df["Age Group"] = new_df["Age Group"].replace({
    '21-30': 20,
    '31-40': 30,
    '41-50': 40,
    '51-60': 50,
    '61-70': 60,
    '71-80': 70,
    '>80': 80,
})

print(new_df)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_data = scaler.fit_transform(new_df)

scaled_df = pd.DataFrame(scaled_data, columns=new_df.columns)
scaled_df = scaled_df.fillna(scaled_df.mean())

print(scaled_df)

from sklearn.decomposition import PCA

# PCA with 3 components
pca = PCA(n_components=3)
pca.fit(new_df)
X_transformed = pca.transform(new_df)

print(X_transformed)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter3D(X_transformed[:, 0], X_transformed[:, 1], X_transformed[:, 2])
ax.set_xlabel('PC1')
ax.set_ylabel('PC2')
ax.set_zlabel('PC3')
plt.show()

"""8. Clustering

*K_MEANS clustering*
"""

from sklearn.cluster import KMeans

# K_MEANS clustering
wcss_values = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10)
    kmeans.fit(new_df)
    wcss_values.append(kmeans.inertia_)

# Plot the WCSS values
plt.plot(range(1, 11), wcss_values)
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

"""Παρατηρουμε στο παραπανω διαγραμμα οτι ο καταλληλος αριθμος clusters ειναι κ = 4 διοτι μετα το 4 το wcss μειωνεται γραμμικα μετα απο εκει"""

from os import kill
from sklearn.cluster import KMeans

# do K-means clustering with k=4
kmeans = KMeans(n_clusters=4, n_init=10)
labels = kmeans.fit_predict(X_transformed)

fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

ax.scatter(X_transformed[:, 0], X_transformed[:, 1], X_transformed[:, 2], c=labels)

ax.set_xlabel('PC1')
ax.set_ylabel('PC2')
ax.set_zlabel('PC3')
ax.set_title('K-means Clustering Results with PCA')

# do the plot
plt.show()

"""*AGGLOMERATIVE clustering*"""

from sklearn.cluster import AgglomerativeClustering

# do Agglomerative clustering with k=4
clustering = AgglomerativeClustering(n_clusters=4)
clusters = clustering.fit_predict(X_transformed)

fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

ax.scatter(X_transformed[:, 0], X_transformed[:, 1], X_transformed[:, 2], c=clusters, cmap='viridis')

ax.set_xlabel('PC1')
ax.set_ylabel('PC2')
ax.set_zlabel('PC3')
ax.set_title('Agglomerative Clustering Results with PCA')

# do the plot
plt.show()